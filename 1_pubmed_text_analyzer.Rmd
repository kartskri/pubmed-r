---
title: "Run a ML Model on the Pub Med database and try to come up with trending Topics LDA Algorithm"
output: html_notebook
---

Import Files

```{r}
# install.packages("tidytext")
# install.packages("reshape2") 
library(tidyverse)
library(tidytext)
library("methods")
library("XML")
library("reshape2")
```


Load PubMed Data from the Excel

```{r}
file_path = "/Users/prolap/v2/hult/events/HultHustle/HultHustle/files/team9_hult_hustle_pubmed_fulldb.csv"
pubmed_csv = read_csv(file_path)
glimpse(pubmed_csv)
```

```{r}
tidy_pubmed <- pubmed_csv %>% 
  # Tokenize the twitter data
  unnest_tokens(word, ArticleTitle) %>% 
  # Remove stop words
  anti_join(stop_words)
```

```{r}
word_counts <- tidy_pubmed %>% 
  count(word) %>% 
  filter(n>200)  %>%
  top_n(20, n)
```

Plot Word Counts

```{r}
word_counts
```
Top Trending Words

```{r}
ggplot(word_counts, aes(x=word, y=n)) +
  geom_col() +
  # Flip the plot coordinates
  coord_flip()
```
```{r}
# install.packages("topicmodels")
library(topicmodels)
```

Come up with Topics

```{r}
dtm_pubmed <- tidy_pubmed %>% 
  count(word, PubMedicationId) %>% 
  cast_dtm(PubMedicationId, word, n)
```

Run the LDA algorithm

```{r}
lda_out <- LDA(
  dtm_pubmed,
  k = 3,
  method = "Gibbs",
  control = list(seed = 42)
)
```


```{r}
glimpse(lda_out)
```


```{r}
lda_topics <- lda_out %>% 
  tidy(matrix="beta") 
```

Create 3 Tops with 15 words under each sectors

```{r}

# Select the top 15 terms by topic and reorder term
word_probs <- lda_topics %>% 
  group_by(topic) %>% 
  top_n(15, beta) %>% 
  ungroup() %>%
  mutate(term2 = fct_reorder(term, beta))

# Plot word_probs2, color and facet based on topic
ggplot(
  word_probs, 
  aes(x=term2, y=beta, fill=as.factor(topic))
) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

```


The first Topic mostly talks about cancer group - 
Second Topic is about Patients and 
Third Topic is mostly about treatment

















